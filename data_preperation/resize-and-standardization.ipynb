{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":8741514,"sourceType":"datasetVersion","datasetId":5248381},{"sourceId":8741521,"sourceType":"datasetVersion","datasetId":5248386}],"dockerImageVersionId":30734,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install natsort","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:14:16.815511Z","iopub.execute_input":"2024-06-21T22:14:16.815916Z","iopub.status.idle":"2024-06-21T22:14:33.663503Z","shell.execute_reply.started":"2024-06-21T22:14:16.815886Z","shell.execute_reply":"2024-06-21T22:14:33.662041Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting natsort\n  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\nDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\nInstalling collected packages: natsort\nSuccessfully installed natsort-8.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pydicom\nimport os\nfrom tqdm import tqdm\nimport numpy as np\nimport concurrent.futures\nimport json\nfrom natsort import natsorted\nfrom pydicom.encaps import encapsulate\nfrom pydicom.uid import JPEG2000Lossless\nimport shutil\nimport random\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:14:33.666287Z","iopub.execute_input":"2024-06-21T22:14:33.666717Z","iopub.status.idle":"2024-06-21T22:14:37.874225Z","shell.execute_reply.started":"2024-06-21T22:14:33.666659Z","shell.execute_reply":"2024-06-21T22:14:37.873029Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data_dir='/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:14:58.047527Z","iopub.execute_input":"2024-06-21T22:14:58.047955Z","iopub.status.idle":"2024-06-21T22:14:58.053185Z","shell.execute_reply.started":"2024-06-21T22:14:58.047919Z","shell.execute_reply":"2024-06-21T22:14:58.052039Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n# def process_serie(patient, serie_id, data_dir):\n#     num_pix_row = []\n#     num_pix_col = []\n#     dicom_dir = f'{data_dir}/train_images/{patient}/{serie_id}'\n#     problematic_serie_ids=[]\n#     for dicom in os.listdir(dicom_dir): \n#         dicom_file = pydicom.dcmread(os.path.join(dicom_dir, dicom))\n#         num_pix_col.append(dicom_file.pixel_array.shape[1])\n#         num_pix_row.append(dicom_file.pixel_array.shape[0])\n\n\n#     x_pixel = max(num_pix_row) if max(num_pix_row) == min(num_pix_row) else 640\n#     y_pixel = max(num_pix_col) if max(num_pix_col) == min(num_pix_col) else 640\n#     dicom_len = len(os.listdir(dicom_dir))\n\n#     size = [x_pixel, y_pixel, dicom_len]\n#     size_and_serie = [serie_id, size]\n#     return size_and_serie\n\n# def process_patient(patient, data_dir):\n#     patient_dir = f'{data_dir}/train_images/{patient}'\n#     results = []\n#     for serie_id in os.listdir(patient_dir):\n#         results.append(process_serie(patient, serie_id, data_dir))\n#     return results\n\n# def main(data_dir):\n#     total_size = []\n#     with concurrent.futures.ProcessPoolExecutor() as executor:\n#         futures = [executor.submit(process_patient, patient, data_dir) for patient in os.listdir(f\"{data_dir}/train_images\")]\n#         for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n#             total_size.extend(future.result())\n#     return total_size\n# data_dir='/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n# total_size = main(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:49:19.288753Z","iopub.execute_input":"2024-06-21T16:49:19.289181Z","iopub.status.idle":"2024-06-21T16:49:19.296090Z","shell.execute_reply.started":"2024-06-21T16:49:19.289147Z","shell.execute_reply":"2024-06-21T16:49:19.294826Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/size-label/list.json', 'r') as f:\n    total_size = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:49:20.122228Z","iopub.execute_input":"2024-06-21T16:49:20.122666Z","iopub.status.idle":"2024-06-21T16:49:20.272188Z","shell.execute_reply.started":"2024-06-21T16:49:20.122633Z","shell.execute_reply":"2024-06-21T16:49:20.271059Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\nwith open('/kaggle/input/label-coordinates/json_label_coordinates (2).json', 'r') as f:\n    label_coordinates = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:16:17.030166Z","iopub.execute_input":"2024-06-21T22:16:17.030603Z","iopub.status.idle":"2024-06-21T22:16:17.246237Z","shell.execute_reply.started":"2024-06-21T22:16:17.030567Z","shell.execute_reply":"2024-06-21T22:16:17.244889Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#####important: I should refine the way to impute missing data\n\ndef produce_label(serie_id,label_coordinates,total_size):\n    same_serie=0\n    for i in range(len(label_coordinates)):\n        if label_coordinates[i]['series_id']==serie_id:\n            index_1=i-1\n            index_2=i\n            same_serie=same_serie+1\n    for j in range(len((total_size))):\n        if int(total_size[j][0])==serie_id:\n            if same_serie==1:\n                            # Extracting x, y, z values\n                x_values_1 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n                y_values_1 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n                z_values_1 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n\n                # Handling NaN values by imputing with the mean\n                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n                label_2=[0]*15\n                label=label_1+label_2\n            elif same_serie==2:\n                x_values_1 = [coord['x'] for coord in label_coordinates[index_1]['coordinates']]\n                y_values_1 = [coord['y'] for coord in label_coordinates[index_1]['coordinates']]\n                z_values_1 = [coord['z'] for coord in label_coordinates[index_1]['coordinates']]\n                # Handling NaN values by imputing with the mean\n                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n                x_values_2 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n                y_values_2 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n                z_values_2 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n\n                # Handling NaN values by imputing with the mean\n                x_values_2 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_2) / total_size[j][1][0] for x in x_values_2]\n                y_values_2 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_2) / total_size[j][1][1]for y in y_values_2]\n                z_values_2 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_2) / total_size[j][1][2] for z in z_values_2]\n                label_2= [val for triplet in zip(x_values_2, y_values_2, z_values_2) for val in triplet]\n                label=label_1+label_2\n    return(label)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:49:22.095818Z","iopub.execute_input":"2024-06-21T16:49:22.096620Z","iopub.status.idle":"2024-06-21T16:49:22.119439Z","shell.execute_reply.started":"2024-06-21T16:49:22.096583Z","shell.execute_reply":"2024-06-21T16:49:22.118304Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"serie_pat_list=[]\nfor i in os.listdir(f'{data_dir}/train_images'):\n    for j in os.listdir(f'{data_dir}/train_images/{i}'):\n        new_list=[i,j]\n        serie_pat_list.append(new_list)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:15:07.262911Z","iopub.execute_input":"2024-06-21T22:15:07.263349Z","iopub.status.idle":"2024-06-21T22:15:12.367815Z","shell.execute_reply.started":"2024-06-21T22:15:07.263314Z","shell.execute_reply":"2024-06-21T22:15:12.366647Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"serie_list=[]\nfor j in range(len(serie_pat_list)):\n    serie_list.append(serie_pat_list[j][1])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:51:57.442239Z","iopub.execute_input":"2024-06-21T17:51:57.442627Z","iopub.status.idle":"2024-06-21T17:51:57.450442Z","shell.execute_reply.started":"2024-06-21T17:51:57.442600Z","shell.execute_reply":"2024-06-21T17:51:57.449253Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def standardize_dicom(serie_pat_list,serie_id,data_dir):\n    for j in range(len(serie_pat_list)):\n        if serie_pat_list[j][1]==serie_id:\n            patient=serie_pat_list[j][0]\n\n    dicom_files = [f for f in os.listdir(f'{data_dir}/train_images/{patient}/{serie_id}')]\n    dicom_files = natsorted(dicom_files)\n    dicom_3d=[]\n    for dicom in dicom_files:\n        dir=f'{data_dir}/train_images/{patient}/{serie_id}/{dicom}'\n        dicom_pix=pydicom.dcmread(dir).pixel_array\n        dicom_pix=dicom_pix/dicom_pix.max()\n        dicom_3d.append(dicom_pix)\n    dicom_3d=np.array(dicom_3d)\n    dicom_3d=torch.tensor(dicom_3d)\n    return(dicom_3d)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:14:05.643534Z","iopub.execute_input":"2024-06-21T22:14:05.643997Z","iopub.status.idle":"2024-06-21T22:14:05.652955Z","shell.execute_reply.started":"2024-06-21T22:14:05.643962Z","shell.execute_reply":"2024-06-21T22:14:05.651645Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with open('resize_standard.py', 'w') as f:\n    f.write(\"\"\"\nimport pydicom\nimport os\nimport numpy as np\nfrom natsort import natsorted\nimport torch\nimport torch.nn.functional as F\ndef standardize_dicom(serie_pat_list,serie_id,data_dir):\n    for j in range(len(serie_pat_list)):\n        if serie_pat_list[j][1]==serie_id:\n            patient=serie_pat_list[j][0]\n\n    dicom_files = [f for f in os.listdir(f'{data_dir}/train_images/{patient}/{serie_id}')]\n    dicom_files = natsorted(dicom_files)\n    dicom_3d=[]\n    for dicom in dicom_files:\n        dir=f'{data_dir}/train_images/{patient}/{serie_id}/{dicom}'\n        dicom_pix=pydicom.dcmread(dir).pixel_array\n        dicom_pix=dicom_pix/dicom_pix.max()\n        dicom_3d.append(dicom_pix)\n    dicom_3d=np.array(dicom_3d)\n    dicom_3d=torch.tensor(dicom_3d)\n    return(dicom_3d)\n\ndef produce_label(serie_id,label_coordinates,total_size):\n    same_serie=0\n    for i in range(len(label_coordinates)):\n        if label_coordinates[i]['series_id']==serie_id:\n            index_1=i-1\n            index_2=i\n            same_serie=same_serie+1\n    for j in range(len((total_size))):\n        if int(total_size[j][0])==serie_id:\n            if same_serie==1:\n                            # Extracting x, y, z values\n                x_values_1 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n                y_values_1 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n                z_values_1 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n\n                # Handling NaN values by imputing with the mean\n                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n                label_2=[0]*15\n                label=label_1+label_2\n            elif same_serie==2:\n                x_values_1 = [coord['x'] for coord in label_coordinates[index_1]['coordinates']]\n                y_values_1 = [coord['y'] for coord in label_coordinates[index_1]['coordinates']]\n                z_values_1 = [coord['z'] for coord in label_coordinates[index_1]['coordinates']]\n                # Handling NaN values by imputing with the mean\n                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n                x_values_2 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n                y_values_2 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n                z_values_2 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n\n                # Handling NaN values by imputing with the mean\n                x_values_2 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_2) / total_size[j][1][0] for x in x_values_2]\n                y_values_2 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_2) / total_size[j][1][1]for y in y_values_2]\n                z_values_2 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_2) / total_size[j][1][2] for z in z_values_2]\n                label_2= [val for triplet in zip(x_values_2, y_values_2, z_values_2) for val in triplet]\n                label=label_1+label_2\n    return(label)\n\ndef resize(dicom_3d,new_shape=(25, 600, 600)):\n    dicom_3d=dicom_3d.unsqueeze(0)\n    dicom_3d=dicom_3d.unsqueeze(0)\n\n    resized_tensor_trilinear = F.interpolate(dicom_3d, new_shape, mode='trilinear', align_corners=False)\n    return(resized_tensor_trilinear)\n\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:24:34.346202Z","iopub.execute_input":"2024-06-21T17:24:34.346640Z","iopub.status.idle":"2024-06-21T17:24:34.357640Z","shell.execute_reply.started":"2024-06-21T17:24:34.346606Z","shell.execute_reply":"2024-06-21T17:24:34.356480Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def resize(dicom_3d,new_shape=(25, 600, 600)):\n    dicom_3d=dicom_3d.unsqueeze(0)\n    dicom_3d=dicom_3d.unsqueeze(0)\n    resized_tensor_trilinear = F.interpolate(dicom_3d, new_shape, mode='trilinear', align_corners=False)\n    return(resized_tensor_trilinear)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T22:16:04.878613Z","iopub.execute_input":"2024-06-21T22:16:04.879011Z","iopub.status.idle":"2024-06-21T22:16:04.885836Z","shell.execute_reply.started":"2024-06-21T22:16:04.878982Z","shell.execute_reply":"2024-06-21T22:16:04.884616Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:01.010810Z","iopub.execute_input":"2024-06-21T17:07:01.011220Z","iopub.status.idle":"2024-06-21T17:07:01.018356Z","shell.execute_reply.started":"2024-06-21T17:07:01.011191Z","shell.execute_reply":"2024-06-21T17:07:01.017165Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}