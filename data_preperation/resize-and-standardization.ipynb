{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64b43da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:14.652420Z",
     "iopub.status.busy": "2024-06-22T22:58:14.651931Z",
     "iopub.status.idle": "2024-06-22T22:58:32.437103Z",
     "shell.execute_reply": "2024-06-22T22:58:32.435441Z"
    },
    "papermill": {
     "duration": 17.79867,
     "end_time": "2024-06-22T22:58:32.440356",
     "exception": false,
     "start_time": "2024-06-22T22:58:14.641686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natsort\r\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\r\n",
      "Installing collected packages: natsort\r\n",
      "Successfully installed natsort-8.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d10a0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:32.456494Z",
     "iopub.status.busy": "2024-06-22T22:58:32.456073Z",
     "iopub.status.idle": "2024-06-22T22:58:39.366355Z",
     "shell.execute_reply": "2024-06-22T22:58:39.364537Z"
    },
    "papermill": {
     "duration": 6.922551,
     "end_time": "2024-06-22T22:58:39.370138",
     "exception": false,
     "start_time": "2024-06-22T22:58:32.447587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import json\n",
    "from natsort import natsorted\n",
    "from pydicom.encaps import encapsulate\n",
    "from pydicom.uid import JPEG2000Lossless\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34199a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:39.389474Z",
     "iopub.status.busy": "2024-06-22T22:58:39.388791Z",
     "iopub.status.idle": "2024-06-22T22:58:39.397309Z",
     "shell.execute_reply": "2024-06-22T22:58:39.396091Z"
    },
    "papermill": {
     "duration": 0.021418,
     "end_time": "2024-06-22T22:58:39.400240",
     "exception": false,
     "start_time": "2024-06-22T22:58:39.378822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir='/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5b590a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:39.416117Z",
     "iopub.status.busy": "2024-06-22T22:58:39.415686Z",
     "iopub.status.idle": "2024-06-22T22:58:39.422702Z",
     "shell.execute_reply": "2024-06-22T22:58:39.421394Z"
    },
    "papermill": {
     "duration": 0.017951,
     "end_time": "2024-06-22T22:58:39.425282",
     "exception": false,
     "start_time": "2024-06-22T22:58:39.407331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def process_serie(patient, serie_id, data_dir):\n",
    "#     num_pix_row = []\n",
    "#     num_pix_col = []\n",
    "#     dicom_dir = f'{data_dir}/train_images/{patient}/{serie_id}'\n",
    "#     problematic_serie_ids=[]\n",
    "#     for dicom in os.listdir(dicom_dir): \n",
    "#         dicom_file = pydicom.dcmread(os.path.join(dicom_dir, dicom))\n",
    "#         num_pix_col.append(dicom_file.pixel_array.shape[1])\n",
    "#         num_pix_row.append(dicom_file.pixel_array.shape[0])\n",
    "\n",
    "\n",
    "#     x_pixel = max(num_pix_row) if max(num_pix_row) == min(num_pix_row) else 640\n",
    "#     y_pixel = max(num_pix_col) if max(num_pix_col) == min(num_pix_col) else 640\n",
    "#     dicom_len = len(os.listdir(dicom_dir))\n",
    "\n",
    "#     size = [x_pixel, y_pixel, dicom_len]\n",
    "#     size_and_serie = [serie_id, size]\n",
    "#     return size_and_serie\n",
    "\n",
    "# def process_patient(patient, data_dir):\n",
    "#     patient_dir = f'{data_dir}/train_images/{patient}'\n",
    "#     results = []\n",
    "#     for serie_id in os.listdir(patient_dir):\n",
    "#         results.append(process_serie(patient, serie_id, data_dir))\n",
    "#     return results\n",
    "\n",
    "# def main(data_dir):\n",
    "#     total_size = []\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         futures = [executor.submit(process_patient, patient, data_dir) for patient in os.listdir(f\"{data_dir}/train_images\")]\n",
    "#         for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "#             total_size.extend(future.result())\n",
    "#     return total_size\n",
    "# data_dir='/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "# total_size = main(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e93cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:39.441750Z",
     "iopub.status.busy": "2024-06-22T22:58:39.440542Z",
     "iopub.status.idle": "2024-06-22T22:58:39.474617Z",
     "shell.execute_reply": "2024-06-22T22:58:39.473349Z"
    },
    "papermill": {
     "duration": 0.045324,
     "end_time": "2024-06-22T22:58:39.477605",
     "exception": false,
     "start_time": "2024-06-22T22:58:39.432281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/size-label/list.json', 'r') as f:\n",
    "    total_size = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e836531b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:39.494390Z",
     "iopub.status.busy": "2024-06-22T22:58:39.493530Z",
     "iopub.status.idle": "2024-06-22T22:58:39.848262Z",
     "shell.execute_reply": "2024-06-22T22:58:39.846868Z"
    },
    "papermill": {
     "duration": 0.366885,
     "end_time": "2024-06-22T22:58:39.851562",
     "exception": false,
     "start_time": "2024-06-22T22:58:39.484677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('/kaggle/input/label-coordinates/json_label_coordinates (2).json', 'r') as f:\n",
    "    label_coordinates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a46fc7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:39.874108Z",
     "iopub.status.busy": "2024-06-22T22:58:39.873186Z",
     "iopub.status.idle": "2024-06-22T22:58:39.904951Z",
     "shell.execute_reply": "2024-06-22T22:58:39.903484Z"
    },
    "papermill": {
     "duration": 0.048527,
     "end_time": "2024-06-22T22:58:39.909091",
     "exception": false,
     "start_time": "2024-06-22T22:58:39.860564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###important: I should refine the way to impute missing data\n",
    "\n",
    "def produce_label(serie_id,label_coordinates,total_size):\n",
    "    same_serie=0\n",
    "    for i in range(len(label_coordinates)):\n",
    "        if label_coordinates[i]['series_id']==serie_id:\n",
    "            index_1=i-1\n",
    "            index_2=i\n",
    "            same_serie=same_serie+1\n",
    "    for j in range(len((total_size))):\n",
    "        if int(total_size[j][0])==serie_id:\n",
    "            if same_serie==1:\n",
    "                            # Extracting x, y, z values\n",
    "                x_values_1 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                y_values_1 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                z_values_1 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "\n",
    "                # Handling NaN values by imputing with the mean\n",
    "                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n",
    "                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n",
    "                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n",
    "                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n",
    "                label_2=[0]*15\n",
    "                label=label_1+label_2\n",
    "            elif same_serie==2:\n",
    "                x_values_1 = [coord['x'] for coord in label_coordinates[index_1]['coordinates']]\n",
    "                y_values_1 = [coord['y'] for coord in label_coordinates[index_1]['coordinates']]\n",
    "                z_values_1 = [coord['z'] for coord in label_coordinates[index_1]['coordinates']]\n",
    "                # Handling NaN values by imputing with the mean\n",
    "                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n",
    "                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n",
    "                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n",
    "                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n",
    "                x_values_2 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                y_values_2 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                z_values_2 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "\n",
    "                # Handling NaN values by imputing with the mean\n",
    "                x_values_2 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_2) / total_size[j][1][0] for x in x_values_2]\n",
    "                y_values_2 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_2) / total_size[j][1][1]for y in y_values_2]\n",
    "                z_values_2 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_2) / total_size[j][1][2] for z in z_values_2]\n",
    "                label_2= [val for triplet in zip(x_values_2, y_values_2, z_values_2) for val in triplet]\n",
    "                label=label_1+label_2\n",
    "    return(label)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65616de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:39.928413Z",
     "iopub.status.busy": "2024-06-22T22:58:39.927976Z",
     "iopub.status.idle": "2024-06-22T22:58:44.685151Z",
     "shell.execute_reply": "2024-06-22T22:58:44.683937Z"
    },
    "papermill": {
     "duration": 4.769169,
     "end_time": "2024-06-22T22:58:44.688467",
     "exception": false,
     "start_time": "2024-06-22T22:58:39.919298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "serie_pat_list=[]\n",
    "for i in os.listdir(f'{data_dir}/train_images'):\n",
    "    for j in os.listdir(f'{data_dir}/train_images/{i}'):\n",
    "        new_list=[i,j]\n",
    "        serie_pat_list.append(new_list)\n",
    "serie_pat_list.remove(['3008676218','542282425'])\n",
    "serie_pat_list.remove(['3008676218','3636216534'])\n",
    "serie_pat_list.remove(['3637444890','3892989905'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5061f5e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:44.706098Z",
     "iopub.status.busy": "2024-06-22T22:58:44.705629Z",
     "iopub.status.idle": "2024-06-22T22:58:44.714069Z",
     "shell.execute_reply": "2024-06-22T22:58:44.712601Z"
    },
    "papermill": {
     "duration": 0.020978,
     "end_time": "2024-06-22T22:58:44.717109",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.696131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "serie_list=[]\n",
    "for j in range(len(serie_pat_list)):\n",
    "    serie_list.append(serie_pat_list[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b334a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:44.733619Z",
     "iopub.status.busy": "2024-06-22T22:58:44.733082Z",
     "iopub.status.idle": "2024-06-22T22:58:44.745467Z",
     "shell.execute_reply": "2024-06-22T22:58:44.744081Z"
    },
    "papermill": {
     "duration": 0.023875,
     "end_time": "2024-06-22T22:58:44.748232",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.724357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize_dicom(serie_pat_list,serie_id,data_dir):\n",
    "    for j in range(len(serie_pat_list)):\n",
    "        if serie_pat_list[j][1]==serie_id:\n",
    "            patient=serie_pat_list[j][0]\n",
    "\n",
    "    dicom_files = [f for f in os.listdir(f'{data_dir}/train_images/{patient}/{serie_id}')]\n",
    "    dicom_files = natsorted(dicom_files)\n",
    "    dicom_3d=[]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for j,dicom in enumerate(dicom_files):\n",
    "\n",
    "        dir=f'{data_dir}/train_images/{patient}/{serie_id}/{dicom}'\n",
    "        dicom_pix=pydicom.dcmread(dir).pixel_array\n",
    "        if j==0:\n",
    "            first_shape=dicom_pix.shape\n",
    "        if dicom_pix.shape!=first_shape:\n",
    "            dicom_pix=dicom_pix.astype('float32')\n",
    "            dicom_pix=torch.from_numpy(dicom_pix).unsqueeze(0).unsqueeze(0)\n",
    "            dicom_pix = F.interpolate(dicom_pix, first_shape, mode='bilinear', align_corners=False)\n",
    "            dicom_pix = dicom_pix.squeeze(0).squeeze(0).numpy()  # Remove batch and channel dimensions\n",
    "        dicom_pix=dicom_pix/dicom_pix.max()\n",
    "        dicom_3d.append(dicom_pix)\n",
    "    dicom_3d=np.array(dicom_3d)\n",
    "    dicom_3d=torch.tensor(dicom_3d)\n",
    "    dicom_3d=dicom_3d.to(device)\n",
    "    return(dicom_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab88e83e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:44.766247Z",
     "iopub.status.busy": "2024-06-22T22:58:44.765640Z",
     "iopub.status.idle": "2024-06-22T22:58:44.778058Z",
     "shell.execute_reply": "2024-06-22T22:58:44.776791Z"
    },
    "papermill": {
     "duration": 0.024596,
     "end_time": "2024-06-22T22:58:44.780631",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.756035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('resize_standard.py', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def standardize_dicom(serie_pat_list,serie_id,data_dir):\n",
    "    for j in range(len(serie_pat_list)):\n",
    "        if serie_pat_list[j][1]==serie_id:\n",
    "            patient=serie_pat_list[j][0]\n",
    "\n",
    "    dicom_files = [f for f in os.listdir(f'{data_dir}/train_images/{patient}/{serie_id}')]\n",
    "    dicom_files = natsorted(dicom_files)\n",
    "    dicom_3d=[]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    for j,dicom in enumerate(dicom_files):\n",
    "\n",
    "        dir=f'{data_dir}/train_images/{patient}/{serie_id}/{dicom}'\n",
    "        dicom_pix=pydicom.dcmread(dir).pixel_array\n",
    "        if j==0:\n",
    "            first_shape=dicom_pix.shape\n",
    "        if dicom_pix.shape!=first_shape:\n",
    "            dicom_pix=dicom_pix.astype('float32')\n",
    "            dicom_pix=torch.from_numpy(dicom_pix).unsqueeze(0).unsqueeze(0)\n",
    "            dicom_pix = F.interpolate(dicom_pix, first_shape, mode='bilinear', align_corners=False)\n",
    "            dicom_pix = dicom_pix.squeeze(0).squeeze(0).numpy()  # Remove batch and channel dimensions\n",
    "        dicom_pix=dicom_pix/dicom_pix.max()\n",
    "        dicom_3d.append(dicom_pix)\n",
    "    dicom_3d=np.array(dicom_3d)\n",
    "    dicom_3d=torch.tensor(dicom_3d)\n",
    "    dicom_3d=dicom_3d.to(device)\n",
    "    return(dicom_3d)\n",
    "\n",
    "def produce_label(serie_id,label_coordinates,total_size):\n",
    "    same_serie=0\n",
    "    for i in range(len(label_coordinates)):\n",
    "        if label_coordinates[i]['series_id']==serie_id:\n",
    "            index_1=i-1\n",
    "            index_2=i\n",
    "            same_serie=same_serie+1\n",
    "    for j in range(len((total_size))):\n",
    "        if int(total_size[j][0])==serie_id:\n",
    "            if same_serie==1:\n",
    "                            # Extracting x, y, z values\n",
    "                x_values_1 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                y_values_1 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                z_values_1 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "\n",
    "                # Handling NaN values by imputing with the mean\n",
    "                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n",
    "                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n",
    "                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n",
    "                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n",
    "                label_2=[0]*15\n",
    "                label=label_1+label_2\n",
    "            elif same_serie==2:\n",
    "                x_values_1 = [coord['x'] for coord in label_coordinates[index_1]['coordinates']]\n",
    "                y_values_1 = [coord['y'] for coord in label_coordinates[index_1]['coordinates']]\n",
    "                z_values_1 = [coord['z'] for coord in label_coordinates[index_1]['coordinates']]\n",
    "                # Handling NaN values by imputing with the mean\n",
    "                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n",
    "                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n",
    "                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n",
    "                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n",
    "                x_values_2 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                y_values_2 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "                z_values_2 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n",
    "\n",
    "                # Handling NaN values by imputing with the mean\n",
    "                x_values_2 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_2) / total_size[j][1][0] for x in x_values_2]\n",
    "                y_values_2 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_2) / total_size[j][1][1]for y in y_values_2]\n",
    "                z_values_2 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_2) / total_size[j][1][2] for z in z_values_2]\n",
    "                label_2= [val for triplet in zip(x_values_2, y_values_2, z_values_2) for val in triplet]\n",
    "                label=label_1+label_2\n",
    "    return(label)\n",
    "\n",
    "def resize(dicom_3d,new_shape=(25, 600, 600)):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dicom_3d = dicom_3d.to(device)\n",
    "    dicom_3d=dicom_3d.unsqueeze(0)\n",
    "    dicom_3d=dicom_3d.unsqueeze(0)\n",
    "    resized_tensor_trilinear = F.interpolate(dicom_3d, new_shape, mode='trilinear', align_corners=False)\n",
    "    return(resized_tensor_trilinear)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2b56c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:44.799047Z",
     "iopub.status.busy": "2024-06-22T22:58:44.797757Z",
     "iopub.status.idle": "2024-06-22T22:58:44.806072Z",
     "shell.execute_reply": "2024-06-22T22:58:44.804795Z"
    },
    "papermill": {
     "duration": 0.021018,
     "end_time": "2024-06-22T22:58:44.808746",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.787728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize(dicom_3d,new_shape=(25, 600, 600)):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dicom_3d = dicom_3d.to(device)\n",
    "    dicom_3d=dicom_3d.unsqueeze(0)\n",
    "    dicom_3d=dicom_3d.unsqueeze(0)\n",
    "    resized_tensor_trilinear = F.interpolate(dicom_3d, new_shape, mode='trilinear', align_corners=False)\n",
    "    return(resized_tensor_trilinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c30d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:44.825333Z",
     "iopub.status.busy": "2024-06-22T22:58:44.824908Z",
     "iopub.status.idle": "2024-06-22T22:58:44.831057Z",
     "shell.execute_reply": "2024-06-22T22:58:44.829651Z"
    },
    "papermill": {
     "duration": 0.017511,
     "end_time": "2024-06-22T22:58:44.833738",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.816227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a109fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T22:58:44.849999Z",
     "iopub.status.busy": "2024-06-22T22:58:44.849604Z",
     "iopub.status.idle": "2024-06-22T22:58:44.855091Z",
     "shell.execute_reply": "2024-06-22T22:58:44.853896Z"
    },
    "papermill": {
     "duration": 0.016885,
     "end_time": "2024-06-22T22:58:44.857973",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.841088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in tqdm(serie_list):\n",
    "#     dicom3d=standardize_dicom(serie_pat_list,i , data_dir)\n",
    "#     final_input=resize(dicom3d).squeeze(0)\n",
    "#     if final_input.shape ==torch.Size([1, 25, 600, 600]):\n",
    "#         pass\n",
    "#     else:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e9576",
   "metadata": {
    "papermill": {
     "duration": 0.006862,
     "end_time": "2024-06-22T22:58:44.872346",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.865484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7f0f7",
   "metadata": {
    "papermill": {
     "duration": 0.006765,
     "end_time": "2024-06-22T22:58:44.886546",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.879781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4770e4",
   "metadata": {
    "papermill": {
     "duration": 0.006765,
     "end_time": "2024-06-22T22:58:44.900557",
     "exception": false,
     "start_time": "2024-06-22T22:58:44.893792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "datasetId": 5248381,
     "sourceId": 8741514,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5248386,
     "sourceId": 8741521,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30734,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.834753,
   "end_time": "2024-06-22T22:58:46.133998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-22T22:58:11.299245",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
