{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":8741514,"sourceType":"datasetVersion","datasetId":5248381},{"sourceId":8741521,"sourceType":"datasetVersion","datasetId":5248386}],"dockerImageVersionId":30734,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install natsort","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:05.258493Z","iopub.execute_input":"2024-06-21T09:18:05.258942Z","iopub.status.idle":"2024-06-21T09:18:23.992159Z","shell.execute_reply.started":"2024-06-21T09:18:05.258891Z","shell.execute_reply":"2024-06-21T09:18:23.990559Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting natsort\n  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\nDownloading natsort-8.4.0-py3-none-any.whl (38 kB)\nInstalling collected packages: natsort\nSuccessfully installed natsort-8.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pydicom\nimport os\nfrom tqdm import tqdm\nimport numpy as np\nimport concurrent.futures\nimport json\nfrom natsort import natsorted\nfrom pydicom.encaps import encapsulate\nfrom pydicom.uid import JPEG2000Lossless\nimport shutil\nimport random\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:23.995279Z","iopub.execute_input":"2024-06-21T09:18:23.995812Z","iopub.status.idle":"2024-06-21T09:18:28.734230Z","shell.execute_reply.started":"2024-06-21T09:18:23.995762Z","shell.execute_reply":"2024-06-21T09:18:28.733021Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_dir='/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:28.736131Z","iopub.execute_input":"2024-06-21T09:18:28.736755Z","iopub.status.idle":"2024-06-21T09:18:28.742767Z","shell.execute_reply.started":"2024-06-21T09:18:28.736719Z","shell.execute_reply":"2024-06-21T09:18:28.741363Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n# def process_serie(patient, serie_id, data_dir):\n#     num_pix_row = []\n#     num_pix_col = []\n#     dicom_dir = f'{data_dir}/train_images/{patient}/{serie_id}'\n#     problematic_serie_ids=[]\n#     for dicom in os.listdir(dicom_dir): \n#         dicom_file = pydicom.dcmread(os.path.join(dicom_dir, dicom))\n#         num_pix_col.append(dicom_file.pixel_array.shape[1])\n#         num_pix_row.append(dicom_file.pixel_array.shape[0])\n\n\n#     x_pixel = max(num_pix_row) if max(num_pix_row) == min(num_pix_row) else 640\n#     y_pixel = max(num_pix_col) if max(num_pix_col) == min(num_pix_col) else 640\n#     dicom_len = len(os.listdir(dicom_dir))\n\n#     size = [x_pixel, y_pixel, dicom_len]\n#     size_and_serie = [serie_id, size]\n#     return size_and_serie\n\n# def process_patient(patient, data_dir):\n#     patient_dir = f'{data_dir}/train_images/{patient}'\n#     results = []\n#     for serie_id in os.listdir(patient_dir):\n#         results.append(process_serie(patient, serie_id, data_dir))\n#     return results\n\n# def main(data_dir):\n#     total_size = []\n#     with concurrent.futures.ProcessPoolExecutor() as executor:\n#         futures = [executor.submit(process_patient, patient, data_dir) for patient in os.listdir(f\"{data_dir}/train_images\")]\n#         for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n#             total_size.extend(future.result())\n#     return total_size\n# data_dir='/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n# total_size = main(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:28.746440Z","iopub.execute_input":"2024-06-21T09:18:28.746935Z","iopub.status.idle":"2024-06-21T09:18:28.762541Z","shell.execute_reply.started":"2024-06-21T09:18:28.746895Z","shell.execute_reply":"2024-06-21T09:18:28.761084Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/size-label/list.json', 'r') as f:\n    total_size = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:28.764668Z","iopub.execute_input":"2024-06-21T09:18:28.765111Z","iopub.status.idle":"2024-06-21T09:18:28.938836Z","shell.execute_reply.started":"2024-06-21T09:18:28.765068Z","shell.execute_reply":"2024-06-21T09:18:28.937610Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/label-coordinates/json_label_coordinates (2).json', 'r') as f:\n    label_coordinates = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:28.940311Z","iopub.execute_input":"2024-06-21T09:18:28.940682Z","iopub.status.idle":"2024-06-21T09:18:29.244768Z","shell.execute_reply.started":"2024-06-21T09:18:28.940651Z","shell.execute_reply":"2024-06-21T09:18:29.243784Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#####important: I should refine the way to impute missing data\n\ndef produce_label(serie_id):\n    same_serie=0\n    for i in range(len(label_coordinates)):\n        if label_coordinates[i]['series_id']==serie_id:\n            index_1=i-1\n            index_2=i\n            same_serie=same_serie+1\n    for j in range(len((total_size))):\n        if int(total_size[j][0])==serie_id:\n            if same_serie==1:\n                            # Extracting x, y, z values\n                x_values_1 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n                y_values_1 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n                z_values_1 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n\n                # Handling NaN values by imputing with the mean\n                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n                label_2=[0]*15\n                label=label_1+label_2\n            elif same_serie==2:\n                x_values_1 = [coord['x'] for coord in label_coordinates[index_1]['coordinates']]\n                y_values_1 = [coord['y'] for coord in label_coordinates[index_1]['coordinates']]\n                z_values_1 = [coord['z'] for coord in label_coordinates[index_1]['coordinates']]\n                # Handling NaN values by imputing with the mean\n                x_values_1 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_1) / total_size[j][1][0] for x in x_values_1]\n                y_values_1 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_1) / total_size[j][1][1] for y in y_values_1]\n                z_values_1 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_1) / total_size[j][1][2] for z in z_values_1]\n                label_1= [val for triplet in zip(x_values_1, y_values_1, z_values_1) for val in triplet]\n                x_values_2 = [coord['x'] for coord in label_coordinates[index_2]['coordinates']]\n                y_values_2 = [coord['y'] for coord in label_coordinates[index_2]['coordinates']]\n                z_values_2 = [coord['z'] for coord in label_coordinates[index_2]['coordinates']]\n\n                # Handling NaN values by imputing with the mean\n                x_values_2 = [x / total_size[j][1][0] if not np.isnan(x) else np.nanmean(x_values_2) / total_size[j][1][0] for x in x_values_2]\n                y_values_2 = [y / total_size[j][1][1] if not np.isnan(y) else np.nanmean(y_values_2) / total_size[j][1][1]for y in y_values_2]\n                z_values_2 = [z / total_size[j][1][2] if not np.isnan(z) else np.nanmean(z_values_2) / total_size[j][1][2] for z in z_values_2]\n                label_2= [val for triplet in zip(x_values_2, y_values_2, z_values_2) for val in triplet]\n                label=label_1+label_2\n    return(label)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:18:29.246090Z","iopub.execute_input":"2024-06-21T09:18:29.246414Z","iopub.status.idle":"2024-06-21T09:18:29.271552Z","shell.execute_reply.started":"2024-06-21T09:18:29.246387Z","shell.execute_reply":"2024-06-21T09:18:29.270239Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def standardize_dicom(patient,serie_id,data_dir):\n    dicom_files = [f for f in os.listdir(f'{data_dir}/train_images/{patient}/{serie_id}')]\n    dicom_files = natsorted(dicom_files)\n    dicom_3d=[]\n    for dicom in dicom_files:\n        dir=f'{data_dir}/train_images/{patient}/{serie_id}/{dicom}'\n        dicom_pix=pydicom.dcmread(dir).pixel_array\n        dicom_pix=dicom_pix/dicom_pix.max()\n        dicom_3d.append(dicom_pix)\n    dicom_3d=torch.tensor(dicom_3d)\n    return(dicom_3d)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:19:34.459354Z","iopub.execute_input":"2024-06-21T09:19:34.459888Z","iopub.status.idle":"2024-06-21T09:19:34.470282Z","shell.execute_reply.started":"2024-06-21T09:19:34.459839Z","shell.execute_reply":"2024-06-21T09:19:34.468111Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dicom_3d=standardize_dicom(3343942613,4231470556,data_dir)\nprint(dicom_3d.unsqueeze(0).shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:19:35.879090Z","iopub.execute_input":"2024-06-21T09:19:35.879478Z","iopub.status.idle":"2024-06-21T09:19:37.249938Z","shell.execute_reply.started":"2024-06-21T09:19:35.879449Z","shell.execute_reply":"2024-06-21T09:19:37.248366Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([1, 22, 384, 384])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2417833851.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n  dicom_3d=torch.tensor(dicom_3d)\n","output_type":"stream"}]},{"cell_type":"code","source":"def resize(dicom_3d,new_shape=(25, 600, 600)):\n    dicom_3d=dicom_3d.unsqueeze(0)\n    dicom_3d=dicom_3d.unsqueeze(0)\n\n    resized_tensor_trilinear = F.interpolate(dicom_3d, new_shape, mode='trilinear', align_corners=False)\n    return(resized_tensor_trilinear)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T09:19:47.379972Z","iopub.execute_input":"2024-06-21T09:19:47.380423Z","iopub.status.idle":"2024-06-21T09:19:47.387392Z","shell.execute_reply.started":"2024-06-21T09:19:47.380387Z","shell.execute_reply":"2024-06-21T09:19:47.385960Z"},"trusted":true},"execution_count":13,"outputs":[]}]}